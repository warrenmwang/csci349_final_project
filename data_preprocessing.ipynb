{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e262a046-f516-44e8-ae65-1e3753450b1c",
   "metadata": {},
   "source": [
    "## Other Modeling Approaches\n",
    "\n",
    "After having tried Association Rule Mining, I have decided that it would be interesting to try to use other methods to produce Anime Recommendations, in order\n",
    "to compare and contrast methods and give a comprehensive final report.\n",
    "\n",
    "In this notebook, we will explore the following methods:\n",
    "\n",
    "- User-based collaborative filtering using `scikit-surprise` library. The idea is that we use a person's profile of anime they have watched and rated to try to find other users who have a similar profile based only on the anime they have watched and rated as well, and then predict how well the person we want to predict for would have rated an anime that the other similar profiles have watched and rated. So we try to find similar watchers and use their ratings to generalize what our person would probably rate the other anime they haven't watched as. Return the predicted higher rated anime.\n",
    "- Feature Similarity using KNN. We have a mix of data types, which makes the problem a bit tricky. We have categorical variables (genre and tags) and numerical variables (number of episodes). In order to use both of these data, we will need to do two things\n",
    "    - normalize the number of episodes to [0,1] since we know that the distribution is NOT gaussian and there are many outliers in the data. the distribution is an exponential distribution.\n",
    "    - one hot encode the genre categorical variables. there are not that many genres, so we can do that.\n",
    "    - one hote encode the tag variables. this is more tricky, because there are a LOT of differing tags. we will need to do more data preprocessing with this and potentially apply dimensionality reduction techniques that will remove the principle components that explain the least variance in the data and keep the ones that explain the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db2200-b42f-4b3f-aed8-7d5dc438d890",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering\n",
    "### Use `scikit-surprise` package for more advanced recommendation system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db2bb61d-d96e-4cd0-9569-b17339dcc391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b27cec0-fe9f-417a-8932-e8d5ac5725f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime_lists = pd.read_csv(\"./data/animelists_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea2f680-3537-40bb-9135-5368eff58c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_cleaned = pd.read_csv(\"./data/users_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197be59b-0000-40d4-9712-df9c606f96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map from name to id\n",
    "userName2userIDMap = {}\n",
    "def foo(row):\n",
    "    global userName2userIDMap\n",
    "    k,v = row.username, row.user_id\n",
    "    if k not in userName2userIDMap:\n",
    "        userName2userIDMap[k] = v\n",
    "\n",
    "df_users_cleaned.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223cb160-8a07-4478-aa3f-615207c4e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reverse map from id to name\n",
    "userID2userNameMap = {}\n",
    "for k,v in userName2userIDMap.items():\n",
    "    userID2userNameMap[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5e6c16e-d562-4925-a233-a9edd0562f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the username maps\n",
    "with open('userName2userIDMap.pkl', 'wb') as f:\n",
    "    pickle.dump(userName2userIDMap, f)\n",
    "\n",
    "with open('userID2userNameMap.pkl', 'wb') as f:\n",
    "    pickle.dump(userID2userNameMap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa4d4d0-e92e-40a6-9e7d-c6f0c3bcbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the usernames into user_ids\n",
    "user_ids = []\n",
    "def foo(row):\n",
    "    global user_ids\n",
    "    user_ids.append(userName2userIDMap[row.username])\n",
    "\n",
    "df_anime_lists.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbf8677d-fbf8-48ff-95f9-113e1f2092e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the ordered list of all user ids for the anime list observations (really long)\n",
    "with open('user_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(user_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc8ed70-5d05-469c-981c-1cd4bea2f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime = pd.read_csv(\"./data/anime_cleaned.csv\")\n",
    "\n",
    "animeID2animeNameMap = {}\n",
    "animeName2animeIDMap = {}\n",
    "\n",
    "def foo(row):\n",
    "    global animeID2animeNameMap, animeName2animeIDMap\n",
    "    id_,title = row.anime_id, row.title\n",
    "    animeID2animeNameMap[id_] = title\n",
    "    animeName2animeIDMap[title] = id_\n",
    "\n",
    "df_anime.apply(foo, axis=1)\n",
    "\n",
    "del df_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c110170-e847-4f4a-83f9-dd976d503655",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('animeID2animeNameMap.pkl', 'wb') as f:\n",
    "    pickle.dump(animeID2animeNameMap, f)\n",
    "\n",
    "with open('animeName2animeIDMap.pkl', 'wb') as f:\n",
    "    pickle.dump(animeName2animeIDMap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073541b7-9d60-4662-a5f0-b455631f109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'user_id': user_ids,\n",
    "    'anime_id': df_anime_lists['anime_id'],\n",
    "    'score': df_anime_lists['my_score'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e87c81-b6c7-4856-8560-5c699672b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_anime_lists\n",
    "del df_users_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ce63be-1f51-4cc8-b43f-5db6b3bdaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_custom.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c0b3ad-b279-463a-80f8-de8982885bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2255153</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2255153</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2255153</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2255153</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2255153</td>\n",
       "      <td>178</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284025</th>\n",
       "      <td>4862000</td>\n",
       "      <td>15611</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284026</th>\n",
       "      <td>4862000</td>\n",
       "      <td>27815</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284027</th>\n",
       "      <td>299167</td>\n",
       "      <td>5945</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284028</th>\n",
       "      <td>263803</td>\n",
       "      <td>1316</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284029</th>\n",
       "      <td>48074</td>\n",
       "      <td>1744</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31284030 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  anime_id  score\n",
       "0         2255153        21      9\n",
       "1         2255153        59      7\n",
       "2         2255153        74      7\n",
       "3         2255153       120      7\n",
       "4         2255153       178      7\n",
       "...           ...       ...    ...\n",
       "31284025  4862000     15611      9\n",
       "31284026  4862000     27815      9\n",
       "31284027   299167      5945      8\n",
       "31284028   263803      1316      9\n",
       "31284029    48074      1744     10\n",
       "\n",
       "[31284030 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e339bf1-7fd4-4697-a3e3-93d52e5d36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31284030 entries, 0 to 31284029\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   anime_id  int64\n",
      " 2   score     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 716.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be0cf3ea-8156-4156-a0c0-3afbeda78eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "0     12111905\n",
       "8      4834595\n",
       "7      4234726\n",
       "9      3443674\n",
       "10     2507404\n",
       "6      2128502\n",
       "5      1085660\n",
       "4       480871\n",
       "3       223202\n",
       "2       130314\n",
       "1       103177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6481d3-a1f4-4339-b53d-e4eb232e5508",
   "metadata": {},
   "source": [
    "remove all observations in which the score is 0, which means user did not give a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fc4106-fc20-4bea-816f-7a9ad1ab9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['score'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc93635d-5b3f-4f76-a9f3-f424a7abbcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "8     4834595\n",
       "7     4234726\n",
       "9     3443674\n",
       "10    2507404\n",
       "6     2128502\n",
       "5     1085660\n",
       "4      480871\n",
       "3      223202\n",
       "2      130314\n",
       "1      103177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d9d2f9d-b490-4803-b9a6-21a41868092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "False    102476\n",
       "True       3926\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out user_ids which have fewer than 5 anime rated. \n",
    "\n",
    "# it looks like we will filter our 3926 users if we do that.\n",
    "(df['user_id'].value_counts() < 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe69528-0021-4be1-a84c-c93a16a56932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19162287 entries, 0 to 31284016\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   anime_id  int64\n",
      " 2   score     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 584.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Count the number of ratings per user\n",
    "ratings_per_user = df['user_id'].value_counts()\n",
    "\n",
    "# Identify users with fewer than 5 ratings\n",
    "users_with_few_ratings = ratings_per_user[ratings_per_user < 5].index\n",
    "\n",
    "# Filter out users with fewer than 5 ratings\n",
    "df = df[~df['user_id'].isin(users_with_few_ratings)]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63944be1-2149-4f71-8415-e76233ebdc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35fd7296-ac07-4458-b886-cf2f792cfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Reader object to parse the file\n",
    "reader = Reader(rating_scale=(1, 10))  # Assuming scores are from 1 to 10 (ignore 0 scores, which mean no rating given.)\n",
    "\n",
    "# Load the dataset\n",
    "data = Dataset.load_from_df(df[['user_id', 'anime_id', 'score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a628f0-1fcc-4cb3-9d2b-640d75c51f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use SVD algorithm\n",
    "# algo = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "\n",
    "# # Run 5-fold cross-validation and print results\n",
    "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d65afb2c-9b91-4f4f-9400-30a3e2e7401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "# https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD\n",
    "\n",
    "# GridSearchCV\n",
    "# https://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.search.GridSearchCV\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "# parameters = {\n",
    "#     'n_factors': [100, 200, 300],\n",
    "#     'n_epochs': [20, 30],\n",
    "#     'lr_all': [0.005, 0.001],\n",
    "#     'reg_all': [0.02, 0.03],\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(algo_class = SVD, \n",
    "#                    param_grid = parameters,\n",
    "#                    measures = ['rmse', 'mae'],\n",
    "#                    n_jobs = 2,\n",
    "#                    cv = 5,\n",
    "#                    refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0fd7428-5d22-4af0-988b-1d84abd0e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result = grid.fit(data)\n",
    "# grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013ce12-ff16-4f4f-ba61-e2dcce4794f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, if we got good enough results, train on everything.\n",
    "# trainset = data.build_full_trainset()\n",
    "# algo = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "# algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df2898-5ad9-4b6e-a741-ed59275f72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(algo, user_id, n=10):\n",
    "    # Assume we have a list of all anime_ids in the dataset\n",
    "    all_anime_ids = set(df['anime_id'].unique())\n",
    "    \n",
    "    # Get the list of anime_ids that the user has already rated\n",
    "    rated_anime_ids = set(df[df['user_id'] == user_id]['anime_id'].unique())\n",
    "    \n",
    "    # Predict ratings for all anime the user hasn't rated\n",
    "    predictions = [algo.predict(user_id, anime_id) for anime_id in all_anime_ids if anime_id not in rated_anime_ids]\n",
    "\n",
    "    # print(predictions)\n",
    "    \n",
    "    # Sort the predictions in descending order of the estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Return the top N anime_ids\n",
    "    top_n_anime_ids = [pred.iid for pred in predictions[:n]]\n",
    "    return top_n_anime_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d9af4-7613-4be5-8f22-3989d0624065",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = list(set(user_ids))\n",
    "unique_user_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989933b-d210-4a08-934b-243dce61d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a untrained algo for comparison?\n",
    "# algo_untrained = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb41f26-8573-41c7-937a-49b9b058cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_user_id in unique_user_ids[:5]:\n",
    "    top_recommendations = get_top_n_recommendations(algo=grid, user_id=str(test_user_id), n=10)\n",
    "    print(f\"Recommendations for {userID2userNameMap[test_user_id]}: \")\n",
    "    for rec in top_recommendations:\n",
    "        print(animeID2animeNameMap[rec])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f41094-5abb-4c84-ac8b-28f51459a1e5",
   "metadata": {},
   "source": [
    "This approach requires that the user be in the dataset so that we know what anime they've watched and what they rated them as in order for us to predict new anime that they haven't watched and would likely rate highly, based on how other people rated those anime and what anime they have rated likely. This is user-based collaborative filtering.\n",
    "\n",
    "\n",
    "Below, we will explore content-based collaborative filtering, which uses the feature information of the content (anime) in order to try to predict anime with similar features to a new user's anime list. We would need to fallback to this approach if the new user is not in the database already, so this is an approach to solve the \"cold start\" problem in recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53c4f1-d17e-4d26-bdf4-d9f3b6f46369",
   "metadata": {},
   "source": [
    "### kNNs\n",
    "\n",
    "This will be the fallback approach. If a new user who has never been in the database comes along with a list of anime they liked, how are we going to use the SVD algo? We can't unless we put this new data point into the dataset and retrain. But that is slow. Therefore, we will need to have a different, fallback method. To keep things simple, we can use only the genre type as a feature of the anime and try to compute distance metrics on those features between different anime. Close anime are similar anime we will recommend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce2776-ee67-46ea-bde5-33a1e20ef0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
