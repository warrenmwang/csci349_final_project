{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae636c6a-e039-4ee2-9adb-aeb806ce54f3",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "We have a large dataset on the anime watchers on the MyAnimeList website. \n",
    "In this notebook, we will explore and discuss the findings of trying to create an Anime recommendation system from the data.\n",
    "\n",
    "## Data\n",
    "In order to solve our objective, we are making use of a Kaggle dataset that essentially includes the three following things sourced from the website MyAnimeList (an online website community/database for people who watch anime):\n",
    "- User List: a snapshot list of all the users in their database and some profile data, including but not limited to their birthdate, gender, location, number of anime watched, etc.\n",
    "- Anime List: a snapshot list of all anime in their database when this dataset was curated\n",
    "- Anime-lists List: a snapshot of the lists of anime each User has interacted with in some way (marked as to watch, watched in entirety or partly, etc.), their ratings, how many comments they left on them, etc.\n",
    "\n",
    "There is a lot of data here to inspect.\n",
    "We note that the kaggle dataset provides different versions of the CSV files, raw, cleaned, and filtered. Under the project time constraints, we only investigated the cleaned csv files and will only be looking at the data inside those files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc131768-b022-4e55-acee-d4a16d3e9451",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "There is a lot of data to be parsed through, so let us take a look at a couple of samples from each relevant csv file.\n",
    "If we take a look at a couple of observations in each CSV file we can see that they contain a lot of useful information.\n",
    "\n",
    "Loading all of the dataframes at once will take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5218280-2c84-443f-b09f-03663ebfb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# association rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# svd\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader\n",
    "\n",
    "# knns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65caf16-051a-4075-9ea2-bbbf6368378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(\"./data/users_cleaned.csv\")\n",
    "df_anime = pd.read_csv(\"./data/anime_cleaned.csv\")\n",
    "df_anime_lists = pd.read_csv(\"./data/animelists_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176922a3-ab2d-4acb-9c44-fcb893b23dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username                               karthiga\n",
       "user_id                                 2255153\n",
       "user_watching                                 3\n",
       "user_completed                               49\n",
       "user_onhold                                   1\n",
       "user_dropped                                  0\n",
       "user_plantowatch                              0\n",
       "user_days_spent_watching              55.091667\n",
       "gender                                   Female\n",
       "location                        Chennai, India \n",
       "birth_date                  1990-04-29 00:00:00\n",
       "access_rank                                 NaN\n",
       "join_date                   2013-03-03 00:00:00\n",
       "last_online                 2014-02-04 01:32:00\n",
       "stats_mean_score                           7.43\n",
       "stats_rewatched                             0.0\n",
       "stats_episodes                             3391\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccadce1d-c41f-4261-b9c6-77d9cd836129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id                                                       11013\n",
       "title                                                  Inu x Boku SS\n",
       "title_english                              Inu X Boku Secret Service\n",
       "title_japanese                                                妖狐×僕SS\n",
       "title_synonyms                                       Youko x Boku SS\n",
       "image_url          https://myanimelist.cdn-dena.com/images/anime/...\n",
       "type                                                              TV\n",
       "source                                                         Manga\n",
       "episodes                                                          12\n",
       "status                                               Finished Airing\n",
       "airing                                                         False\n",
       "aired_string                            Jan 13, 2012 to Mar 30, 2012\n",
       "aired                     {'from': '2012-01-13', 'to': '2012-03-30'}\n",
       "duration                                             24 min. per ep.\n",
       "rating                                     PG-13 - Teens 13 or older\n",
       "score                                                           7.63\n",
       "scored_by                                                     139250\n",
       "rank                                                          1274.0\n",
       "popularity                                                       231\n",
       "members                                                       283882\n",
       "favorites                                                       2809\n",
       "background         Inu x Boku SS was licensed by Sentai Filmworks...\n",
       "premiered                                                Winter 2012\n",
       "broadcast                                         Fridays at Unknown\n",
       "related            {'Adaptation': [{'mal_id': 17207, 'type': 'man...\n",
       "producer           Aniplex, Square Enix, Mainichi Broadcasting Sy...\n",
       "licensor                                            Sentai Filmworks\n",
       "studio                                              David Production\n",
       "genre                         Comedy, Supernatural, Romance, Shounen\n",
       "opening_theme                                  ['\"Nirvana\" by MUCC']\n",
       "ending_theme       ['#1: \"Nirvana\" by MUCC (eps 1, 11-12)', '#2: ...\n",
       "duration_min                                                    24.0\n",
       "aired_from_year                                               2012.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e554b3-ec8a-47e0-b733-9561ee2a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username                          karthiga\n",
       "anime_id                                21\n",
       "my_watched_episodes                    586\n",
       "my_start_date                   0000-00-00\n",
       "my_finish_date                  0000-00-00\n",
       "my_score                                 9\n",
       "my_status                                1\n",
       "my_rewatching                          NaN\n",
       "my_rewatching_ep                         0\n",
       "my_last_updated        2013-03-03 10:52:53\n",
       "my_tags                                NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime_lists.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5886a-4ceb-434c-89a1-2468f1ea5859",
   "metadata": {},
   "source": [
    "In order to process the data, we need to know which models we will use so that we can process the data FOR the modeling. So let's talk about the models that we will use.\n",
    "\n",
    "1. Association Rule Mining\n",
    "   > In the world of association rule mining, we make predictions based off of patterns in a dataset of sets of objects and how frequent some items or sets show up give us information about how likely they are to appear with other items. We will need to construct transactions (sets) of anime that are watched together. To keep things simple, we will consider a transaction to be the set of anime each user has watched. After we have produced our strong association rules, we will then create a powerset of the itemsets (yes that's a lot) of the user input list of anime to predict on, and try to match the greatest itemset in the antecedents of the rules, from most items to least items, from the best rules to the worst rules, and return the consequents. With some parameters, we can control if we just return the top consequent itemset or all of the matched consequents from the rules. Therefore, for Association Rule Mining we will need to use data from `df_anime_list`.\n",
    "3. SVD\n",
    "   > To use SVD, we will need to view our data and how we make predictions differently. We use the idea of user-based collaborative filtering, which basically leverages the anime ratings that other users give to their watched anime, and what ratings the current user has given to their watched anime, to predict what the current user would rate anime that they have NOT watched that other users have watched and rated in order to give them recommendations. After training on our dataset, we can use this algorithm to make rating predictions on the entire set of anime that the current user has NOT watched. Then, we simply return the top k anime to recommend k anime to the user. Therefore, for SVD we will need to use data from `df_anime_list` and `df_users`. \n",
    "5. kNNs\n",
    "   > For kNNs, we want to consider the other features that the previous two methods have not touched (Association Rules extract wisdom from the crowds and basically makes an implicit assumption that most people will actually seek out anime that they like to watch and SVD also uses wisdom of the crowds and the ratings that they give to anime to know what anime are good and which ones are bad). We will use the genre information of anime to find \"similar\" anime based off of how many genres they match to other anime. Therefore, for kNNs we will need to use data from `df_anime`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2150d-cbc5-4347-8a9f-ac8bba9b65b1",
   "metadata": {},
   "source": [
    "## General Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb8620-8467-47c0-a4ba-1202b7b84138",
   "metadata": {},
   "source": [
    "### Utility Mapping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68599f2-0777-4f1e-8796-c46351bce3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to and from username to id\n",
    "userName2userIDMap = {}\n",
    "userID2userNameMap = {}\n",
    "\n",
    "def foo(row):\n",
    "    global userName2userIDMap, userID2userNameMap\n",
    "    k,v = row.username, row.user_id\n",
    "    if k not in userName2userIDMap:\n",
    "        userName2userIDMap[k] = v\n",
    "    if v not in userID2userNameMap:\n",
    "        userID2userNameMap[v] = k\n",
    "\n",
    "df_users.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37bf2c5-797e-4ba9-b08b-03ca9a9f8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to and from anime name to id\n",
    "\n",
    "animeID2animeNameMap = {}\n",
    "animeName2animeIDMap = {}\n",
    "\n",
    "def foo(row):\n",
    "    global animeID2animeNameMap, animeName2animeIDMap\n",
    "    id_,title = row.anime_id, row.title\n",
    "    animeID2animeNameMap[id_] = title\n",
    "    animeName2animeIDMap[title] = id_\n",
    "\n",
    "df_anime.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca79b6-96d7-4ad9-8003-10870e4c196b",
   "metadata": {},
   "source": [
    "### Association Rule Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7cf340-144f-4b9f-af07-889b4672000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extraneous columns that we are not using for association rule mining.\n",
    "df_association_rules = df_anime_lists.drop(columns=df_anime_lists.columns[2:])\n",
    "\n",
    "# let's try to downcast the int data types.\n",
    "intCols = df_association_rules.select_dtypes('int').columns\n",
    "df_association_rules[intCols] = df_association_rules[intCols].apply(pd.to_numeric, downcast='integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07582218-91a2-4c5b-9a30-96032b2a0b66",
   "metadata": {},
   "source": [
    "### SVD Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3456eb86-37f3-4393-9597-1da79452587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the usernames into user_ids\n",
    "user_ids = []\n",
    "def foo(row):\n",
    "    global user_ids\n",
    "    user_ids.append(userName2userIDMap[row.username])\n",
    "\n",
    "df_anime_lists.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bec015-01e3-4807-a307-3ac4c9fd06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svd = pd.DataFrame(data={\n",
    "    'user_id': user_ids,\n",
    "    'anime_id': df_anime_lists['anime_id'],\n",
    "    'score': df_anime_lists['my_score'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cca33-57e4-419a-a10e-86ca9db01806",
   "metadata": {},
   "source": [
    "### kNN Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b27132b-d772-4d3b-a9ab-8d07df718ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove anime that have no genres, since we are relying solely on the genre features to determine similarity.\n",
    "df_knn = df_anime[~df_anime['genre'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa130fca-6b4e-4db0-9e2d-1f4f6f0a4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of the genres\n",
    "all_genre_set = set()\n",
    "\n",
    "def foo(row):\n",
    "    x = row.genre\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        print(f'anomoly genre: {x}')\n",
    "\n",
    "    if ',' not in x:\n",
    "        all_genre_set.add(x)\n",
    "        return\n",
    "    \n",
    "    x = x.replace(' ', '').split(',')\n",
    "    if len(x) > 0:\n",
    "        for g in x:\n",
    "            all_genre_set.add(g)\n",
    "    \n",
    "\n",
    "df_knn.apply(foo, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f89d6c8-905c-4f97-8cc0-fb9c9779e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_417481/2620349618.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_knn['genre_list'] = df_knn['genre'].apply(split_genres)\n"
     ]
    }
   ],
   "source": [
    "# Clean and split the genre string into a list for each row\n",
    "def split_genres(genre):\n",
    "    if not isinstance(genre, str):\n",
    "        return []\n",
    "    return [g.strip() for g in genre.split(',')]\n",
    "\n",
    "# Apply the function to the genre column to split the genres\n",
    "df_knn['genre_list'] = df_knn['genre'].apply(split_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d81685-6948-40cf-b2de-9996b46e6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the one-hot encoding columns\n",
    "genre_df = pd.DataFrame(0, index=df_knn.index, columns=list(all_genre_set))\n",
    "\n",
    "# Populate the DataFrame: for each anime, set 1 for genres it has\n",
    "for index, row in df_knn.iterrows():\n",
    "    genres = row['genre_list']\n",
    "    for genre in genres:\n",
    "        if genre in all_genre_set:  # This check is technically redundant but safe\n",
    "            genre_df.at[index, genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60109c33-c6c5-4e7e-8890-f5d395f64ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = df_knn[['anime_id']].join(genre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71446b25-2ccd-4e71-8dfc-6f3d05fb3646",
   "metadata": {},
   "source": [
    "### Garbage Collect the Raw DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68c02edf-a882-43ca-a158-411f068a13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_anime\n",
    "del df_users\n",
    "del df_anime_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e4b1a-c939-4401-be40-89d123794527",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Since we needed to talk about the models in the previous section to know how to preprocess the data, we will now simply run the models and demonstrate how they work on some sample input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5548b-ebac-42d5-83a3-141d15fa2a50",
   "metadata": {},
   "source": [
    "### Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab24155-06f1-4341-82de-5e491f66e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewTopKRules(rules : pd.DataFrame, metric : str | list[str], k : int, ascending : bool = False) -> pd.DataFrame:\n",
    "    '''\n",
    "    return a subset of the rules dataframe \n",
    "    given the metric / metrics to sort by\n",
    "    top k to return\n",
    "    and whether to be sorted in ascending or descending order\n",
    "    '''\n",
    "    return rules.sort_values(by=metric, ascending=ascending).head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c21f71-bb98-4f20-941d-e9e631362dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55ea448d-b5a7-42d2-8e2e-89b607ec46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_recommend_anime(rules : pd.DataFrame,  userList : list[str] , short : bool = False) -> list[str]:\n",
    "    '''\n",
    "    Given a list of anime the user watches, return a list of anime recommendations.\n",
    "\n",
    "    This is the better version that tries to match as much of animes in the original list.\n",
    "    Then we start to add more recommendations by using rules that match fewer and fewer until we are matching rules from singleton animes from userList.\n",
    "\n",
    "    Input data:\n",
    "        userList - list of user anime to make predictions off of.\n",
    "        short - boolean to toggle whether to return a short list of recommended anime or not. the short version \n",
    "            is just the consequent anime(s) in the first association rule whose antecedent matches with\n",
    "            the longest subset in userList.\n",
    "\n",
    "    Return data format:\n",
    "        (anime_recommendation, score1, score2)\n",
    "            score1 - this is the number of animes used to match the rule for this rec (higher is better)\n",
    "            score2 - this is how far away from the strongest/top rule this rec was found at (lower is better)\n",
    "    \n",
    "    '''\n",
    "    assert isinstance(userList, list), 'input not of type list'\n",
    "    \n",
    "    retList = []\n",
    "    retAnime = set()\n",
    "\n",
    "    # create all subsets with at least 1 anime\n",
    "    tmp = [x for x in powerset(userList)]\n",
    "    tmp = list(filter(lambda x : True if len(x) >= 1 else False, tmp))\n",
    "    tmp = sorted(tmp, key=lambda x: len(x), reverse=True)\n",
    "    tmp = [frozenset(x) for x in tmp]\n",
    "\n",
    "    for subset in tmp:\n",
    "        score2 = 0\n",
    "        for index, row in rules.sort_values(by=['confidence', 'lift'], ascending=False).iterrows():\n",
    "            if subset == row.antecedents:\n",
    "                consequents = list(row.consequents)\n",
    "                for a in consequents:\n",
    "\n",
    "                    # don't add this anime if we already got it\n",
    "                    if a in retAnime: continue\n",
    "\n",
    "                    retAnime.add(a)\n",
    "\n",
    "                    score1 = len(subset)\n",
    "                    retList.append((a, score1, score2))\n",
    "\n",
    "                # only capture one consequent(s) if short is True\n",
    "                if short:\n",
    "                    break\n",
    "\n",
    "            score2 += 1\n",
    "    \n",
    "    # sort return list of anime by descending number of anime from \n",
    "    retList = sorted(retList, key=lambda x : x[1], reverse=True)\n",
    "    \n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "448af99a-ca67-4f47-82e9-ecb3ac9e493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "----phoebelyn       [21, 120, 853, 957, 1571, 1579, 1698, 1735, 1,...\n",
       "---L-AND-AME-4EV                                           [20, 1535]\n",
       "--AnimeBoy--        [21, 59, 74, 210, 232, 249, 853, 1557, 1735, 2...\n",
       "--Etsuko--          [3092, 4814, 7054, 7674, 9926, 11013, 11123, 1...\n",
       "--FallenAngel--     [21, 59, 210, 249, 269, 853, 857, 957, 1579, 1...\n",
       "                                          ...                        \n",
       "zzshinzozz          [21, 232, 249, 1735, 7054, 9513, 9863, 10800, ...\n",
       "zzvl                [120, 269, 853, 4224, 6045, 7054, 9926, 10800,...\n",
       "zzz275              [59, 120, 853, 1571, 1698, 2104, 4477, 1, 16, ...\n",
       "zzzcielo            [21, 74, 269, 853, 857, 957, 1698, 1735, 3731,...\n",
       "zzzzz-chan          [21, 59, 120, 210, 232, 269, 853, 857, 1735, 3...\n",
       "Name: anime_id, Length: 108709, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = df_association_rules.groupby('username')['anime_id'].apply(list)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f9f810-a3be-469c-9e05-7f8d386e21ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username\n",
       "----phoebelyn       [One Piece, Fruits Basket, Ouran Koukou Host C...\n",
       "---L-AND-AME-4EV                                 [Naruto, Death Note]\n",
       "--AnimeBoy--        [One Piece, Chobits, Gakuen Alice, Ranma ½, Ca...\n",
       "--Etsuko--          [Junjou Romantica, Junjou Romantica 2, Kaichou...\n",
       "--FallenAngel--     [One Piece, Chobits, Ranma ½, InuYasha, Bleach...\n",
       "                                          ...                        \n",
       "zzshinzozz          [One Piece, Cardcaptor Sakura, InuYasha, Narut...\n",
       "zzvl                [Fruits Basket, Bleach, Ouran Koukou Host Club...\n",
       "zzz275              [Chobits, Fruits Basket, Ouran Koukou Host Clu...\n",
       "zzzcielo            [One Piece, Gakuen Alice, Bleach, Ouran Koukou...\n",
       "zzzzz-chan          [One Piece, Chobits, Fruits Basket, Ranma ½, C...\n",
       "Name: anime_id, Length: 108709, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = transactions.apply(lambda x: [animeID2animeNameMap[i] for i in x])\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e40847f-7260-4d85-b1ad-1b44a88a8ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295017</td>\n",
       "      <td>(Accel World)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279075</td>\n",
       "      <td>(Air)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344323</td>\n",
       "      <td>(Akame ga Kill!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.569962</td>\n",
       "      <td>(Angel Beats!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429983</td>\n",
       "      <td>(Ano Hi Mita Hana no Namae wo Bokutachi wa Mad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                                           itemsets\n",
       "0  0.295017                                      (Accel World)\n",
       "1  0.279075                                              (Air)\n",
       "2  0.344323                                   (Akame ga Kill!)\n",
       "3  0.569962                                     (Angel Beats!)\n",
       "4  0.429983  (Ano Hi Mita Hana no Namae wo Bokutachi wa Mad..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_SUPPORT = 0.26\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_association_rules_1 = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "frequent_itemsets = apriori(df_association_rules_1, min_support=MIN_SUPPORT, use_colnames=True)\n",
    "\n",
    "frequent_itemsets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2c17ff-1556-425b-baa5-f8b77cce0fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Accel World)</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.295017</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.276518</td>\n",
       "      <td>0.937295</td>\n",
       "      <td>1.630070</td>\n",
       "      <td>0.106882</td>\n",
       "      <td>6.777762</td>\n",
       "      <td>0.548282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Angel Beats!)</td>\n",
       "      <td>(Akame ga Kill!)</td>\n",
       "      <td>0.569962</td>\n",
       "      <td>0.344323</td>\n",
       "      <td>0.289139</td>\n",
       "      <td>0.507295</td>\n",
       "      <td>1.473312</td>\n",
       "      <td>0.092888</td>\n",
       "      <td>1.330770</td>\n",
       "      <td>0.747043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Akame ga Kill!)</td>\n",
       "      <td>(Angel Beats!)</td>\n",
       "      <td>0.344323</td>\n",
       "      <td>0.569962</td>\n",
       "      <td>0.289139</td>\n",
       "      <td>0.839732</td>\n",
       "      <td>1.473312</td>\n",
       "      <td>0.092888</td>\n",
       "      <td>2.683239</td>\n",
       "      <td>0.489962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Akame ga Kill!)</td>\n",
       "      <td>(Code Geass: Hangyaku no Lelouch)</td>\n",
       "      <td>0.344323</td>\n",
       "      <td>0.622957</td>\n",
       "      <td>0.268975</td>\n",
       "      <td>0.781171</td>\n",
       "      <td>1.253973</td>\n",
       "      <td>0.054477</td>\n",
       "      <td>1.723002</td>\n",
       "      <td>0.308894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Akame ga Kill!)</td>\n",
       "      <td>(Death Note)</td>\n",
       "      <td>0.344323</td>\n",
       "      <td>0.748153</td>\n",
       "      <td>0.297170</td>\n",
       "      <td>0.863055</td>\n",
       "      <td>1.153580</td>\n",
       "      <td>0.039563</td>\n",
       "      <td>1.839031</td>\n",
       "      <td>0.203047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        antecedents                        consequents  antecedent support  \\\n",
       "0     (Accel World)                 (Sword Art Online)            0.295017   \n",
       "1    (Angel Beats!)                   (Akame ga Kill!)            0.569962   \n",
       "2  (Akame ga Kill!)                     (Angel Beats!)            0.344323   \n",
       "3  (Akame ga Kill!)  (Code Geass: Hangyaku no Lelouch)            0.344323   \n",
       "4  (Akame ga Kill!)                       (Death Note)            0.344323   \n",
       "\n",
       "   consequent support   support  confidence      lift  leverage  conviction  \\\n",
       "0            0.575003  0.276518    0.937295  1.630070  0.106882    6.777762   \n",
       "1            0.344323  0.289139    0.507295  1.473312  0.092888    1.330770   \n",
       "2            0.569962  0.289139    0.839732  1.473312  0.092888    2.683239   \n",
       "3            0.622957  0.268975    0.781171  1.253973  0.054477    1.723002   \n",
       "4            0.748153  0.297170    0.863055  1.153580  0.039563    1.839031   \n",
       "\n",
       "   zhangs_metric  \n",
       "0       0.548282  \n",
       "1       0.747043  \n",
       "2       0.489962  \n",
       "3       0.308894  \n",
       "4       0.203047  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_CONFIDENCE = 0.5\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=MIN_CONFIDENCE)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "692008de-1e89-4bf0-bd59-032af2411b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29542</th>\n",
       "      <td>(Sword Art Online II, Shingeki no Kyojin, Mira...</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.267650</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.266832</td>\n",
       "      <td>0.996941</td>\n",
       "      <td>1.733802</td>\n",
       "      <td>0.112932</td>\n",
       "      <td>138.940596</td>\n",
       "      <td>0.577911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29149</th>\n",
       "      <td>(Sword Art Online II, Fullmetal Alchemist: Bro...</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.262287</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.261423</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>1.733388</td>\n",
       "      <td>0.110607</td>\n",
       "      <td>128.914253</td>\n",
       "      <td>0.573523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19248</th>\n",
       "      <td>(Angel Beats!, Sword Art Online II, Shingeki n...</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.274375</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.273464</td>\n",
       "      <td>0.996681</td>\n",
       "      <td>1.733349</td>\n",
       "      <td>0.115698</td>\n",
       "      <td>128.044301</td>\n",
       "      <td>0.583059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28405</th>\n",
       "      <td>(Death Note, Sword Art Online II, Shingeki no ...</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.283804</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.282819</td>\n",
       "      <td>0.996532</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>122.542129</td>\n",
       "      <td>0.590614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29834</th>\n",
       "      <td>(Steins;Gate, Sword Art Online II, Shingeki no...</td>\n",
       "      <td>(Sword Art Online)</td>\n",
       "      <td>0.268671</td>\n",
       "      <td>0.575003</td>\n",
       "      <td>0.267733</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>1.733048</td>\n",
       "      <td>0.113246</td>\n",
       "      <td>121.694977</td>\n",
       "      <td>0.578375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             antecedents         consequents  \\\n",
       "29542  (Sword Art Online II, Shingeki no Kyojin, Mira...  (Sword Art Online)   \n",
       "29149  (Sword Art Online II, Fullmetal Alchemist: Bro...  (Sword Art Online)   \n",
       "19248  (Angel Beats!, Sword Art Online II, Shingeki n...  (Sword Art Online)   \n",
       "28405  (Death Note, Sword Art Online II, Shingeki no ...  (Sword Art Online)   \n",
       "29834  (Steins;Gate, Sword Art Online II, Shingeki no...  (Sword Art Online)   \n",
       "\n",
       "       antecedent support  consequent support   support  confidence      lift  \\\n",
       "29542            0.267650            0.575003  0.266832    0.996941  1.733802   \n",
       "29149            0.262287            0.575003  0.261423    0.996703  1.733388   \n",
       "19248            0.274375            0.575003  0.273464    0.996681  1.733349   \n",
       "28405            0.283804            0.575003  0.282819    0.996532  1.733090   \n",
       "29834            0.268671            0.575003  0.267733    0.996508  1.733048   \n",
       "\n",
       "       leverage  conviction  zhangs_metric  \n",
       "29542  0.112932  138.940596       0.577911  \n",
       "29149  0.110607  128.914253       0.573523  \n",
       "19248  0.115698  128.044301       0.583059  \n",
       "28405  0.119631  122.542129       0.590614  \n",
       "29834  0.113246  121.694977       0.578375  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewTopKRules(rules, metric=['confidence', 'lift'], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d078d1ed-78ed-4b47-82c0-cd4637f06ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Death Note', 2, 2774),\n",
       " ('Code Geass: Hangyaku no Lelouch', 2, 8640),\n",
       " ('Naruto: Shippuuden', 2, 9880),\n",
       " ('Fullmetal Alchemist: Brotherhood', 2, 10111),\n",
       " ('Angel Beats!', 2, 10486),\n",
       " ('Bleach', 2, 10991),\n",
       " ('Clannad', 2, 11446),\n",
       " ('Sword Art Online', 2, 11773),\n",
       " ('Shingeki no Kyojin', 2, 12910),\n",
       " ('Elfen Lied', 2, 12922),\n",
       " ('Durarara!!', 2, 14836),\n",
       " ('Soul Eater', 2, 14951),\n",
       " ('Bakemonogatari', 2, 15679),\n",
       " ('Steins;Gate', 2, 16403),\n",
       " ('Suzumiya Haruhi no Yuuutsu', 2, 16528),\n",
       " ('Tengen Toppa Gurren Lagann', 2, 17482),\n",
       " ('Mirai Nikki (TV)', 2, 12158),\n",
       " ('Toradora!', 2, 13958),\n",
       " ('Ao no Exorcist', 2, 14595),\n",
       " ('Fairy Tail', 2, 15433),\n",
       " ('Tokyo Ghoul', 2, 17109),\n",
       " ('Highschool of the Dead', 2, 17700),\n",
       " ('Ano Hi Mita Hana no Namae wo Bokutachi wa Mada Shiranai.', 2, 14927),\n",
       " ('Another', 2, 15101),\n",
       " ('No Game No Life', 2, 15168),\n",
       " ('Noragami', 2, 17728),\n",
       " ('Psycho-Pass', 2, 18017),\n",
       " ('Naruto', 2, 19293),\n",
       " ('One Punch Man', 2, 19727),\n",
       " ('Hataraku Maou-sama!', 2, 19980),\n",
       " ('Code Geass: Hangyaku no Lelouch R2', 2, 20159),\n",
       " ('Mahou Shoujo Madoka★Magica', 2, 20256),\n",
       " ('Chuunibyou demo Koi ga Shitai!', 2, 20501),\n",
       " ('Kill la Kill', 2, 20571),\n",
       " ('Guilty Crown', 2, 20690),\n",
       " ('Hyouka', 2, 20850),\n",
       " ('Clannad: After Story', 2, 21638),\n",
       " ('Fate/Zero', 2, 22615),\n",
       " ('Sakurasou no Pet na Kanojo', 2, 23143),\n",
       " ('Sen to Chihiro no Kamikakushi', 2, 23148),\n",
       " ('Fullmetal Alchemist', 1, 20377),\n",
       " ('One Piece', 1, 27442),\n",
       " ('Darker than Black: Kuro no Keiyakusha', 1, 30384),\n",
       " ('Neon Genesis Evangelion', 1, 31488),\n",
       " ('Cowboy Bebop', 1, 32049),\n",
       " ('Fate/stay night', 1, 32605),\n",
       " ('K-On!', 1, 25107),\n",
       " ('Kaichou wa Maid-sama!', 1, 29139),\n",
       " ('Higurashi no Naku Koro ni', 1, 29153),\n",
       " ('Zero no Tsukaima', 1, 29430),\n",
       " ('Byousoku 5 Centimeter', 1, 29868),\n",
       " ('Ore no Imouto ga Konnani Kawaii Wake ga Nai', 1, 30528),\n",
       " ('Ookami to Koushinryou', 1, 30532),\n",
       " ('Ouran Koukou Host Club', 1, 31329),\n",
       " ('Shakugan no Shana', 1, 31427),\n",
       " ('Kimi ni Todoke', 1, 31712),\n",
       " ('Toaru Majutsu no Index', 1, 32246),\n",
       " ('Lucky☆Star', 1, 32333),\n",
       " ('Deadman Wonderland', 1, 32598),\n",
       " ('Baccano!', 1, 33489),\n",
       " ('Tonari no Kaibutsu-kun', 1, 33646),\n",
       " ('NHK ni Youkoso!', 1, 33665),\n",
       " ('Sword Art Online II', 1, 28259),\n",
       " ('Akame ga Kill!', 1, 29205),\n",
       " ('Kiseijuu: Sei no Kakuritsu', 1, 30358),\n",
       " ('Boku dake ga Inai Machi', 1, 30624),\n",
       " ('Shigatsu wa Kimi no Uso', 1, 30758),\n",
       " ('Kyoukai no Kanata', 1, 32198),\n",
       " ('Death Parade', 1, 32285),\n",
       " ('Yahari Ore no Seishun Love Comedy wa Machigatteiru.', 1, 32579),\n",
       " ('Shingeki no Kyojin Season 2', 1, 33536)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_recommend_anime(rules, ['Naruto', 'Toradora!', 'Shingeki no Kyojin'], short=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc2390-95d5-433e-b0ce-7ce192554d93",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "In our initial testing, we used GridSearch to find the best parameters among a small set of 120 different configurations for the SVD algorithm. From the GridSearch run, we will be using the following parameters for our SVD:\n",
    "```\n",
    "{'n_factors': 300, 'n_epochs': 20, 'lr_all': 0.001, 'reg_all': 0.03}\n",
    "```\n",
    "that yielded a RMSE of `2.8689316031185306`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5f164aa-38c5-44db-9629-8fc4a3d11fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_get_top_n_recommendations(df : pd.DataFrame, algo : surprise.prediction_algorithms.matrix_factorization.SVD | surprise.model_selection.search.GridSearchCV, user_id : int, n : int=10):\n",
    "    # Get anime_ids that the user has NOT rated\n",
    "    tmp = df[df['user_id'] == user_id]\n",
    "    rated_anime_ids = tmp['anime_id']\n",
    "    all_anime_ids = pd.Series(data=df['anime_id'].unique())\n",
    "    not_rated_anime_ids = all_anime_ids[~all_anime_ids.isin(rated_anime_ids)]\n",
    "    \n",
    "    # Predict ratings for all anime the user hasn't rated\n",
    "    user_id = str(user_id)\n",
    "    predictions = [algo.predict(user_id, anime_id) for anime_id in not_rated_anime_ids]\n",
    "    \n",
    "    # Sort the predictions in descending order of the estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Return the top N anime_ids\n",
    "    top_n_anime_ids = [pred.iid for pred in predictions[:n]]\n",
    "    return top_n_anime_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bdbe42b-d32d-403f-ae2b-c2f5bad4c38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x79c2b6e49a80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best configuration found by GridSearch\n",
    "svd = SVD(n_factors = 300,\n",
    "          n_epochs = 20,\n",
    "          lr_all = 0.001, \n",
    "          reg_all = 0.03)\n",
    "\n",
    "# Train on the whole dataset\n",
    "reader = Reader(rating_scale=(1, 10)) \n",
    "data = Dataset.load_from_df(df_svd, reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# train!\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bb3dc4e-c50f-4bc7-816b-0953b2967be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = list(set(user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f034260d-0201-4af9-97fa-7a810a3c0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Kinnnnnnnnnnnnn: \n",
      "\tSen to Chihiro no Kamikakushi\n",
      "\tHowl no Ugoku Shiro\n",
      "\tMononoke Hime\n",
      "\tFinal Fantasy VII: Advent Children\n",
      "\tTonari no Totoro\n",
      "\n",
      "Recommendations for weiswhit77: \n",
      "\tShingeki no Kyojin\n",
      "\tMononoke Hime\n",
      "\tKimi no Na wa.\n",
      "\tOne Punch Man\n",
      "\tCode Geass: Hangyaku no Lelouch R2\n",
      "\n",
      "Recommendations for Kumi-: \n",
      "\tHowl no Ugoku Shiro\n",
      "\tMononoke Hime\n",
      "\tDragon Ball Z\n",
      "\tFinal Fantasy VII: Advent Children\n",
      "\tTonari no Totoro\n",
      "\n",
      "Recommendations for Danieru-sama: \n",
      "\tInterstella5555: The 5tory of The 5ecret 5tar 5ystem\n",
      "\tToradora!\n",
      "\tPokemon: The Origin\n",
      "\tDetective Conan Movie 01: The Timed Skyscraper\n",
      "\tHotaru no Haka\n",
      "\n",
      "Recommendations for Hintermute: \n",
      "\tDeath Note\n",
      "\tKimi no Na wa.\n",
      "\tOne Punch Man\n",
      "\tCode Geass: Hangyaku no Lelouch R2\n",
      "\tFinal Fantasy VII: Advent Children\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_user_id in random.choices(unique_user_ids, k=5):\n",
    "    top_recommendations = svd_get_top_n_recommendations(df=df_svd, algo=svd, user_id=test_user_id, n=5)\n",
    "    print(f\"Recommendations for {userID2userNameMap[test_user_id]}: \")\n",
    "    for rec in top_recommendations:\n",
    "        print('\\t' + animeID2animeNameMap[rec])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025456d1-b208-4937-9996-a1e26e75d249",
   "metadata": {},
   "source": [
    "### kNNs\n",
    "\n",
    "Now we will aim to utilize the genre information to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ccd1d5a-af3d-4d86-837f-77b1cd30433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_recommend_similar_anime(liked_anime_ids, df_encoded, knn_model, top_m=5):\n",
    "    recommendations = []\n",
    "    \n",
    "    for anime_id in liked_anime_ids:\n",
    "        # Find the one-hot encoded vector for the liked anime\n",
    "        anime_vector = df_encoded[df_encoded['anime_id'] == anime_id].drop(['anime_id', 'genre', 'genre_list'], axis=1, errors='ignore')\n",
    "        \n",
    "        # Use the KNN model to find similar anime\n",
    "        distances, indices = knn_model.kneighbors(anime_vector, n_neighbors=top_m + 1)\n",
    "        \n",
    "        # Get the anime_ids of the recommended anime, excluding the first one (itself)\n",
    "        similar_anime_ids = df_encoded.iloc[indices[0], :]['anime_id'].values[1:]\n",
    "        \n",
    "        recommendations.extend(similar_anime_ids)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    recommendations =  list(set(recommendations))\n",
    "\n",
    "    # Remove anime (if any in list) that were in the user input\n",
    "    ret = []\n",
    "    for x in recommendations:\n",
    "        if x not in liked_anime_ids:\n",
    "            ret.append(x)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2a356a1-32b1-4273-a578-d51b2c90196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop non-genre columns to get the feature set X\n",
    "X = df_knn.drop(['anime_id'], axis=1)\n",
    "\n",
    "# Initialize and fit the KNN model\n",
    "knn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "knn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74b50e24-2b31-4d6f-9612-fe3e6cb58ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Anime IDs:\n",
      "\tDigimon Frontier\n",
      "\tNaruto: Takigakure no Shitou - Ore ga Eiyuu Dattebayo!\n",
      "\tOne Piece: Episode of Merry - Mou Hitori no Nakama no Monogatari\n",
      "\tOne Piece: Long Ring Long Land-hen\n",
      "\tDuel Masters VSR\n",
      "\tOne Piece: Episode of Sabo - 3 Kyoudai no Kizuna Kiseki no Saikai to Uketsugareru Ishi\n",
      "\tDuel Masters Charge\n",
      "\tNinkuu: Knife no Bohyou\n",
      "Recommended Anime IDs:\n",
      "\tShingeki no Kyojin Season 2\n",
      "\tShingeki no Kyojin: Ano Hi Kara\n",
      "\tKaze no Youjinbou\n",
      "\tShingeki no Kyojin OVA\n",
      "\tShingeki no Kyojin Movie 1: Guren no Yumiya\n"
     ]
    }
   ],
   "source": [
    "# Test input anime names\n",
    "liked_animes = [['One Piece', 'Naruto'], ['Shingeki no Kyojin']]\n",
    "\n",
    "for liked_anime in liked_animes:\n",
    "    # Convert from name to ID\n",
    "    liked_anime_ids = [animeName2animeIDMap[x] for x in liked_anime]\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommendations = knn_recommend_similar_anime(liked_anime_ids, df_knn, knn, top_m=5)\n",
    "    \n",
    "    # Convert from id to name\n",
    "    recommendations = [animeID2animeNameMap[x] for x in recommendations]\n",
    "    \n",
    "    print(\"Recommended Anime IDs:\")\n",
    "    for x in recommendations:\n",
    "        print('\\t' + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea9c53-677e-4e02-b969-92b7a1a37ada",
   "metadata": {},
   "source": [
    "## Performance Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959b1f1-0748-41f6-a145-07ec997c4d6b",
   "metadata": {},
   "source": [
    "### Association Rules\n",
    "When we generate the frequent itemsets using the apriori algorithm with a minimum support of `0.26` that allows us to generate `5452` of high quality frequent itemsets.\n",
    "Then, we create our association rules from those frequent itemsets, picking out only the rules with a minimum confidence of `0.5` that leaves us with `33713` usable rules.'\n",
    "Sorting by `confidence` and `lift` measures, our top rule has a confidence of `0.996941` and a lift of `1.733802`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003d3b0-80b7-4dee-8c0f-fe56b6844afd",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "We can measure our performance with using the SVD algorithm to predict ratings by using RMSE and MAE comparing the predicted ratings with the actual ratings that people gave anime on a scale of 1 to 10. From our grid search results, we see the following:\n",
    "\n",
    "```python\n",
    "grid.best_params\n",
    "```\n",
    "```\n",
    "{'rmse': {'n_factors': 300, 'n_epochs': 20, 'lr_all': 0.001, 'reg_all': 0.03},\n",
    " 'mae': {'n_factors': 200, 'n_epochs': 20, 'lr_all': 0.001, 'reg_all': 0.03}}\n",
    "```\n",
    "```python\n",
    "grid.best_score\n",
    "```\n",
    "```\n",
    "{'rmse': 2.8689316031185306, 'mae': 2.222182058129826}\n",
    "```\n",
    "This means that our best predictor was able to predict ratings within an error of ~2-3 point different, which is not ideal to be honest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470e3c2-ca6c-4020-8e01-28be0d0d44f9",
   "metadata": {},
   "source": [
    "### kNNs\n",
    "\n",
    "Based on the way we modeled this problem using kNNs, I think it would be infeasible to quantify the performance of this model that simply generates an order of \"closest to furthest\" away anime in terms of number of overlapping genres that are actually a useful / relevant recommendation to a user without some ground truth of user ratings/reviews of how relevant the recommendations are to them in comparison to the other methods we have tried in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a1e07-bc77-4aea-9fdd-7f325e6b47b9",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Association Rule Mining\n",
    "The association rules work pretty well, considering that it only uses the information inherent in the sets of anime that each user watches. We leverage the data in the wisdom of the crowds, assuming that most people interact with anime that they actually like on the MyAnimeList site. The way we use the association rules we find from the dataset would give the opposite effect of what we want if most of the people only interacted with anime that they deeply disliked. We would then have created an \"anime to stay away from\" recommender instead. If it is not explicit, this approach thus does not make any use of the score / rating that the users give to the anime that they watch.\n",
    "\n",
    "That is were the next method comes in to try to leverage that scoring information.\n",
    "\n",
    "### SVD\n",
    "\n",
    "Using the SVD method, we are limited to predicting anime for user profiles that are in the database already. We can predict new anime to watch for users who have given ratings on other anime they liked / disliked. Using gridsearch to look for the best configuration from a set of SVD predictors, we find that the best one performs ok, but not that great. Given that the RMSE is ~2 - 3 score rating, that's quite significant. Future work would be to try out more parameters, and perhaps a more powerful SVD configuration.\n",
    "\n",
    "### kNNs\n",
    "When using kNNs, we needed to be wary of what kinds of features to use from the dataset. In our experimentation, we tried to recommend anime similar based off of genre and type. Recommendations on genre alone seemed pretty good, so we thought adding the type feature would also be good, but adding that in and testing it out, it was not as good just using it as a human. Since the type categories were mutually exclusive, if you had a list of TV anime, you would only be recommended TV anime. You won't be recommended any the other types like Movies or OVA. This didn't make sense from a design standpoint, so we removed it and for our comparisons between different modeling standpoints, we only used kNNs that worked on one hot encoded genre information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554076a3-f0f4-45ad-a5fb-6ec47a299ec3",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "To create recommendations for current users in the MyAnimeList database, we would recommend using the SVD method that we have, as that takes into account the user's past history of ratings. If the user just wants similar anime based on the genre, we would recommend using the kNN recommendation method. And finally, if we want to make predictions to new users who don't have a focus on wanting to watch anime from similar genre, and they are NOT in our database, then we would recommend using the Association Rule method. By investigating different methods of creating anime recommendations, we have covered different use cases that a user might want. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
